{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e139318f-4e2a-491b-8cac-d187e8811749",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Read mapping and differential coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20947abb-ecfe-4aa0-8046-75d6c7f97531",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Intoduction\n",
    "\n",
    "As per the general prokaryote metagenomics pipeline materials, now that we have a final set of dereplicated genomes (full and/or partial) we can calculate differntial coverage profiles across samples by mapping sequencing reads for each sample back to the dereplicated genome set.\n",
    "\n",
    "Mapping reads derived from DNA will give genomic coverage profiles, while mapping RNAseq reads will give gene transcriptional profiles.\n",
    "\n",
    "There are several common options available for read mapping software (e.g. *Bowtie*, *Bowtie2*, *BBMap*), each with slightly different behaviour. Below is an example using *BBMap*.\n",
    "\n",
    "In the example that follows, we will map the **trimmed and filtered sequencing reads** (the data set used as input into the assembly step) back to the dereplicated set of viral contigs (together with an associated prokaryote metagenome-assembled genome (MAGs) set, if available).\n",
    "\n",
    "NOTE:\n",
    "\n",
    "- If you also have a dereplicated set of prokaryote metagenome-assembled genomes (MAGs) from the same data set, it can be valuable to first collate the viral and prokaryote genomes together to then generate the read mapping index. This can be important especially in the case where viral genomes contain genes that are very similar or identical to those also found in prokaryote genomes (such as host-derived auxiliary metabolic genes). If prokaryote MAGs or contigs are not also included here, reads that are actually derived from the prokaryote genome abundance or transcription can be erroneously mapped to the viral genomes, falsely inflating their coverage.\n",
    "  - One example from our experience: photosynthesis genes found in cyanophage can falsely have RNAseq reads mapped to them that were in fact derived from cyanobacterial photosynthetic gene transcription.\n",
    "  - Also note that even by including both prokaryote and viral genomic material together in read mapping, in cases where the genes are *identical* in both, mapped reads can be randomly split between the two (depending on read mapping settings). In this case, the viral gene coverage (genomic and/or transcriptional) could once again be falsely inflated. In such cases it pays to be mindful of results and ground-truth them to other sources (for example, comparing transcription and/or genomic coverage of genes of interest with patterns across the rest of the genome in question, etc.)\n",
    "- For data generated from sequecing of prokaryote isolate cultures, the read mapping process here likely gives you less ecologically relevant information compared with environmental metagenomics data, but can still give you an indication if, for example, viruses are replicating at the time of sampling (i.e. if coverage of viral genomic regions is considerably higher than the rest of the host genome). If this is of interest, run this separately for each isolate and their suite of associated virus(es) (i.e. map reads from one isolate to a file of concatenated viral sequences identified in *that* isolate (e.g. the checkv-filtered output from `virome_per_sample_derep.py`) together with the assembled isolate genome). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a18189-f1c0-4c4a-926d-a34b7ff29692",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96148d2-c289-481b-a424-33b9be5599e5",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Data prep: collate with prokaryote data\n",
    "\n",
    "If you have dereplicated prokaryote data (such as metagenome-assembled genomes) available from the same data set, you can concatenate these into one fasta file together with the viral contigs prior to generating the read mapping index.\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5efb0a3-8016-4c14-a54b-b978e13304f3",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "cd /working/dir\n",
    "mkdir -p 3.read_mapping\n",
    "\n",
    "cat 1.viral_identification/6.checkv_vOTUs/vOTUs.checkv_filtered.fna /path/to/bin_files/*.fna > 3.read_mapping/DNAviral_and_prokBIN_contigs.fna\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00406933-fa92-4cc9-9b5b-5805e0e85ff5",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d633f3-f7a2-4754-9b08-121d9fc05991",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## *BBMap*: build reference index\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a31ed9-9b46-427d-a04b-4ad92fc60623",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH -A your_project_account\n",
    "#SBATCH -J 5_wgs_read_mapping_index\n",
    "#SBATCH --time 00:05:00\n",
    "#SBATCH --mem 12GB\n",
    "#SBATCH --ntasks 1\n",
    "#SBATCH --cpus-per-task 30\n",
    "#SBATCH -e 5_wgs_read_mapping_index.err\n",
    "#SBATCH -o 5_wgs_read_mapping_index.out\n",
    "\n",
    "# Load dependencies\n",
    "module purge\n",
    "module load BBMap/38.90-gimkl-2020a\n",
    "\n",
    "# Set up working directory\n",
    "cd /working/dir/3.read_mapping\n",
    "\n",
    "# Build index \n",
    "bbmap.sh -Xmx12g ref=DNAviral_and_prokBIN_contigs.fna\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d8965b-aaec-49fb-8071-753a77d6ceb2",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b79114f-aed7-4888-9e60-3dc94c75c29e",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## WGS read mapping (genome coverage)\n",
    "\n",
    "In the example below, we will first map the trimmed and filtered sequencing reads to the mapping index created above. The `covstats` and `statsfile` can be helpful outputs, so have been included here. But the key outputs are the `.sam` files.\n",
    "\n",
    "Here, we will also run `pileup.sh` on the `.sam` output files to generate the `rpkm=...covstats_pileup.txt` output file. In the subsequent step, we can pass this *pileup* output file to the script `summarise_counts.py` to calculate normalised differential coverage profiles across samples. \n",
    "\n",
    "NOTE: \n",
    "\n",
    "- the read directory (`READ_DIR` variable in the script below) here points to the `1a.QC_Filtered_trimmomatic/` data. If you also included the subsequent host filtering step, this would instead point to `1b.QC_Filtered_host/` (and input file names would have to be modified accordingly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef49eb9e-f79a-411f-8c92-29f2dc911dc3",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH -A your_project_account\n",
    "#SBATCH -J 5_wgs_read_mapping\n",
    "#SBATCH --time 02:30:00\n",
    "#SBATCH --mem 100GB\n",
    "#SBATCH --ntasks 1\n",
    "#SBATCH --array=1-9\n",
    "#SBATCH --cpus-per-task 30\n",
    "#SBATCH -e 5_wgs_read_mapping_%a.err\n",
    "#SBATCH -o 5_wgs_read_mapping_%a.out\n",
    "\n",
    "# Load dependencies\n",
    "module purge\n",
    "module load BBMap/38.90-gimkl-2020a\n",
    "\n",
    "# Set up working directories\n",
    "cd /working/dir/3.read_mapping\n",
    "mkdir -p WGS\n",
    "\n",
    "READ_DIR=/path/to/wgs/1a.QC_Filtered_trimmomatic\n",
    "\n",
    "# Run read mapping\n",
    "srun bbmap.sh \\\n",
    "t=30 -Xmx130g ambiguous=best minid=0.95 \\\n",
    "in1=${READ_DIR}/S${SLURM_ARRAY_TASK_ID}_R1.fastq \\\n",
    "in2=${READ_DIR}/S${SLURM_ARRAY_TASK_ID}_R2.fastq \\\n",
    "covstats=WGS/S${SLURM_ARRAY_TASK_ID}.covstats.txt \\\n",
    "statsfile=WGS/S${SLURM_ARRAY_TASK_ID}.statsfile.txt \\\n",
    "out=WGS/S${SLURM_ARRAY_TASK_ID}.sam\n",
    "\n",
    "# Pileup\n",
    "pileup.sh \\\n",
    "in=WGS/S${SLURM_ARRAY_TASK_ID}.sam \\\n",
    "rpkm=WGS/S${SLURM_ARRAY_TASK_ID}.covstats_pileup.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f25ccf-b6e9-4cad-b791-b640cd8a8381",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Calculate (normalised) differential coverage across samples\n",
    "\n",
    "We can now compile a counts table of read counts per contig per sample using the script `summarise_counts.py`. \n",
    "\n",
    "This script returns sets of columns of raw and normalised read counts per sample for each contig included in the read mapping index. Normalisation can be calculated based on *total* sequencing read depth per sample or by *mapped* read counts, and outputs include TPM, RPKM, and (optionally) TMM. It is up to the user to determine the most appropriate normalisation method for your data set. \n",
    "\n",
    "This script (and the required associated R script `summarise_counts.R`) is available in the `../scripts/` directory.\n",
    "\n",
    "NOTE:\n",
    "\n",
    "- There can be many options available for this step in the process. `summarise_counts.py` was generated in our group to handle this in an automated manner, but feel free to experiment with other options\n",
    "- **TMM normalisation**: We can also optionally provide a **sample mapping file** (see below) of relevant sample groupings if we wish to include TMM normalisation (sample groups information is required for calucating TMM via the R package *edgeR*)\n",
    "- **Genome level count summaries**: We can also optionally provide a **genome2contig lookup table** (see below) matching contig IDs to each genome to generate 'genome'-level coverage summeries (especially relevant for, e.g., prokaryote metagenome-assembled genomes which contain more than one contig per genome). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8141f456-e16c-4201-aa3a-e427330a01ca",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "#### Create Sample mapping file (if also calculating TMM)\n",
    "\n",
    "Providing an optional sample mapping enables also calculating TMM normalisation (via *edgeR*). The required format of the mapping file is two columns: \n",
    "\n",
    "1. `sampleID`: Filename substrings (one per file) that identify the sample (e.g. S1.covstats_pileup.txt substring could be `S1`). (NOTE: if a wildcard is included in the python call, this must not include any of the substring after the wildcard)\n",
    "1. `group`: Group or category that each sample belongs to\n",
    "1. (OPTIONAL) `lib.size`: Optional third column of read counts per sample. This is required for normalising by total library size when inputting featurecounts data (e.g. for read mapping coverage for individual genes). When using *pileup* output (e.g. for wgs (genome) coverage), the script automatically retrieves this information from the `...covstats_pileup.txt` files.\n",
    "\n",
    "For example: \n",
    "\n",
    "| sampleID | group |\n",
    "| :--: | :--: |\n",
    "| S1 | Water_Fresh |\n",
    "| S2 | Water_Fresh |\n",
    "| S3 | Water_Brackish |\n",
    "| S4 | Water_Brackish |\n",
    "| S5 | Water_Brackish |\n",
    "| S6 | Water_Brackish |\n",
    "| S7 | Water_Brackish |\n",
    "| S8 | Water_Marine |\n",
    "| S9 | Water_Marine |\n",
    "\n",
    "A simple bash script example has been provided below to automate this process. (In this example, total library size is also extracted from the `...covstats_pileup.txt` files to include in the mapping file, but this is not essential). But note that this can sometimes be easier to simply manually create the mapping file (e.g. via *nano* or some equivalent)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c254f2ff-7236-4f86-87cf-c8625111a802",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "cd /working/dir\n",
    "\n",
    "# Generate sample mapping file\n",
    "echo -e \"sampleID\\tgroup\\tlib.size\" > 3.read_mapping/WGS/wgs_sample_mapping_file.txt\n",
    "for filename in $(ls 3.read_mapping/WGS/*covstats_pileup.txt); do\n",
    "    entry=$(echo ${filename} | sed -e 's/\\(S[0-9]*\\)\\..*/\\1/g' -e 's/.*\\/\\(.*\\)/\\1/g')\n",
    "    if [[ ${entry} == *\"S1\"* ]] || [[ ${entry} == *\"S2\"* ]]; then\n",
    "        group='Water_Fresh'\n",
    "    elif [[ ${entry} == *\"S3\"* ]] || [[ ${entry} == *\"S4\"* ]] || [[ ${entry} == *\"S5\"* ]] || [[ ${entry} == *\"S6\"* ]] || [[ ${entry} == *\"S7\"* ]]; then\n",
    "        group='Water_Brackish'\n",
    "    elif [[ ${entry} == *\"S8\"* ]] || [[ ${entry} == *\"S9\"* ]]; then\n",
    "        group='Water_Marine'\n",
    "    fi\n",
    "    libsize=$(grep '#Reads' ${filename} | sed 's/#Reads\\s//')\n",
    "    echo -e \"${entry}\\t${group}\\t${libsize}\" >> 3.read_mapping/WGS/wgs_sample_mapping_file.txt\n",
    "done\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf80ca8-0041-4c63-8c3f-dee5b85f3e59",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "#### Create genome2contig_lookupTable.tsv\n",
    "\n",
    "A lookup table matching contig IDs to separate genomes can be useful, particularly in the case of binned sets of contigs (e.g. metagenome-assembled genomes). Including this table in the subsequent `summarise_counts.py` step also generates 'genome' level summaries of read coverage (rather than just contig-level coverage stats).\n",
    "\n",
    "NOTE: This may ultimately be put into a script for ease of use. But for now we can use the python code below to automatically generate a single lookup table for both the viral contig data set and binned prokaryote metagenome-assembled genomes (if available)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbdeb5c-fb05-4939-8c9f-228b19bfef5f",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "cd /working/dir\n",
    "\n",
    "# Load python\n",
    "module purge\n",
    "module load Python/3.8.2-gimkl-2020a\n",
    "python3\n",
    "### Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Bio.SeqIO.FastaIO import SimpleFastaParser\n",
    "import re\n",
    "import os\n",
    "\n",
    "# Compile bin2contig table\n",
    "with open('3.read_mapping/genome2contig_lookupTable.tsv', 'w') as write_file:\n",
    "    # header\n",
    "    write_file.write('binID\\tcontigID\\n')\n",
    "    # viral contigs\n",
    "    with open('1.viral_identification/6.checkv_vOTUs/vOTUs.checkv_filtered.fna', 'r') as read_fasta:\n",
    "        for name, seq in SimpleFastaParser(read_fasta):\n",
    "            write_file.write(name + '\\t' + name + '\\n')\n",
    "    # Prok bins\n",
    "    binfiles_directory = os.fsencode('/path/to/bin_files')\n",
    "    for file in os.listdir(binfiles_directory):\n",
    "        filename = os.fsdecode(file)\n",
    "        binID = os.path.splitext(filename)[0]\n",
    "        with open('/path/to/bin_files/' + filename, 'r') as read_fasta:\n",
    "            for name, seq in SimpleFastaParser(read_fasta):\n",
    "                write_file.write(binID + '\\t' + name + '\\n')\n",
    "\n",
    "quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc73e6d9-4a27-4b04-8db6-494fd3b85bb7",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "#### Run summarise_counts.py\n",
    "\n",
    "NOTE:\n",
    "\n",
    "- `--sample_mapping_file` and `--genome_mapping_file` are  optional. If including the former, TMM normalisation will also be calculated. If including the latter, a genome-level summary file will also be generated (read counts per all contigs in each *genome* rather than per contig). The genome summary file includes summed raw counts, as well normalisation based on library size (total or mapped, depending on the setting) and genome size (length of all included contigs).\n",
    "- `--genome_libSize_norm` determines whether to normalise to the *minimum* read depth of any of the samples, or to the *mean* read depth.\n",
    "- `--lib_norm` sets whether to normalise based on total read depth per sample or mapped reads depth.\n",
    "- `--count_threshold` sets a filter that zeros out raw read counts for any contig in a given sample that fall below this threshold (to help filter out spurious read mapping). You can experiment with this to determine what seems appropriate for your data.\n",
    "- `--read_counts` outputs a summary table of total and mapped read counts per sample for future reference, and `--output` is the final differential coverage count table (including multiple normalisation metrics)\n",
    "  - n.b. if a genome_mapping_file is included, the genome level summary takes this file name and appends 'genomeSummary'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1258b895-17a4-481a-9a92-8c9033258039",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "cd /working/dir\n",
    "\n",
    "# Load python and R\n",
    "module purge\n",
    "module load Python/3.8.2-gimkl-2020a\n",
    "module load R-bundle-Bioconductor/3.15-gimkl-2022a-R-4.2.1\n",
    "\n",
    "# Run summarise_counts.py \n",
    "# Note: the quotes in the --input line are required to enable the wildcard (*) to be interpreted correctly\n",
    "/path/to/scripts/summarise_counts.py \\\n",
    "    --input '3.read_mapping/WGS/*.covstats_pileup.txt' \\\n",
    "    --format pileup \\\n",
    "    --sample_mapping_file 3.read_mapping/WGS/wgs_sample_mapping_file.txt \\\n",
    "    --genome_mapping_file 3.read_mapping/genome2contig_lookupTable.tsv \\\n",
    "    --genome_libSize_norm min \\\n",
    "    --lib_norm total \\\n",
    "    --count_threshold 10 \\\n",
    "    --read_counts 3.read_mapping/WGS/wgs_summary_read_counts.tsv \\\n",
    "    --output 3.read_mapping/WGS/wgs_summary_count_table.tsv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9092ffd7-f205-4938-8304-988dec31720e",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b17c58-d157-4cf0-8d57-14139b34f4bc",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## WTS read mapping (gene transcription)\n",
    "\n",
    "If you also have RNAseq data available, we can follow a similar process as above to generate differential coverage of transcribed genes across samples.\n",
    "\n",
    "Here, we can first map trimmed and filtered RNAseq reads to the same read mapping index generated above. A gene coordinates file (start and end coordinates and strandedness of predicted genes within each contig; GTF or SAF format) needs to then be generated to pass to a program such as *featureCounts* to generate a gene counts output for each sample. \n",
    "\n",
    "The *featureCounts* output can be passed into `summarise_counts.py` to generate a count table of normalised differential transcription coverage per gene per sample. As above, providing a genome mapping file will also output summed counts of gene transcription per genome, and providing a mapping file will also calculate TMM normalisation **as well as *edgeR* differentially expressed genes (DEG) analysis across sample groups** (Note, however, that the latter may not be entirely appropriate for metagenome RNAseq data sets (as was designed for single genome transcription (DEG) analyses), and so should be viewed with caution. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd176dd-a931-4969-9e49-39349c81f8d5",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "#### WTS read mapping\n",
    "\n",
    "Map trimmed and filtered RNAseq reads to the same read mapping reference generated above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ee9d3b-2008-42f2-a44d-36dede93db62",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH -A your_project_account\n",
    "#SBATCH -J 5_wts_read_mapping\n",
    "#SBATCH --time 08:00:00\n",
    "#SBATCH --mem 94GB\n",
    "#SBATCH --ntasks 1\n",
    "#SBATCH --array=1-9\n",
    "#SBATCH --cpus-per-task 30\n",
    "#SBATCH -e 5_wts_read_mapping_%a.err\n",
    "#SBATCH -o 5_wts_read_mapping_%a.out\n",
    "\n",
    "# Load dependencies\n",
    "module purge\n",
    "module load BBMap/38.90-gimkl-2020a\n",
    "module load SAMtools/1.15.1-GCC-11.3.0\n",
    "\n",
    "# Set up working directories\n",
    "cd /working/dir/3.read_mapping\n",
    "mkdir -p WTS/\n",
    "\n",
    "READ_DIR=/path/to/wts/1.trimmed_filtered\n",
    "\n",
    "# Run read mapping\n",
    "srun bbmap.sh \\\n",
    "t=30 -Xmx94g ambiguous=best minid=0.95 \\\n",
    "in1=${READ_DIR}/S${SLURM_ARRAY_TASK_ID}_R1.fastq \\\n",
    "in2=${READ_DIR}/S${SLURM_ARRAY_TASK_ID}_R2.fastq \\\n",
    "covstats=WTS/S${SLURM_ARRAY_TASK_ID}.covstats.txt \\\n",
    "statsfile=WTS/S${SLURM_ARRAY_TASK_ID}.statsfile.txt \\\n",
    "out=WTS/S${SLURM_ARRAY_TASK_ID}.sam\n",
    "# convert to bam\n",
    "samtools sort -@ 10 -o WTS/S${SLURM_ARRAY_TASK_ID}.bam WTS/S${SLURM_ARRAY_TASK_ID}.sam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be047b9a-9b29-4270-9176-48fee6b8a3c5",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "#### In development...\n",
    "\n",
    "A script will be developed to generate the appropriate gene coordinates file required by *featureCounts*, based on the gene calling outputs from *DRAM-v*. This is currently a work in progress. In the meantime, you will need to generate one yourself (GTF or SAF format).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95bed04-380b-4dc7-acac-06ccf134be1b",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "#### Run *featureCounts* \n",
    "\n",
    "NOTE: *featureCounts* is not currently available in NeSI. You will need to install this separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7bc372-4fcb-4c5c-b376-5383b7b51185",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Set up directories\n",
    "cd /working/dir\n",
    "mkdir -p 3.read_mapping/featureCounts\n",
    "\n",
    "# Run featureCounts\n",
    "/path/to/Software/featureCounts \\\n",
    "-p -T 8 -t exon -F SAF \\\n",
    "-a /path/to/gene_coords.SAF \\\n",
    "-o 3.read_mapping/featureCounts/gene_counts.txt \\\n",
    "3.read_mapping/WTS/*.bam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ede028-fb32-4c12-a8b1-2a8a243ef2f8",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "#### Generate sample mapping file\n",
    "\n",
    "As above, this can optionally be included in `summarise_counts.py` to also generate TMM normalised coverages and also run *edgeR* differential gene expression analysis. \n",
    "\n",
    "The required format is as above (see WGS read mapping section). \n",
    "\n",
    "The bash script below is one way of generating this in a semi-automated manner, this time extracting the information (including library size) from the *BBMap* `...statsfile.txt` output file. \n",
    "\n",
    "Note: \n",
    "\n",
    "- In the case of using *featureCounts* outputs with `summarise_counts.py`, it is necessary to include the library size in the mapping file here if `--lib_norm` is set to `total` when running `summarise_counts.py`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da13509-2b8f-4052-a776-5a4e82c92b81",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "cd /working/dir\n",
    "\n",
    "# Generate mapping file\n",
    "echo -e \"sampleID\\tgroup\\tlib.size\" > 3.read_mapping/WTS/wts_sample_mapping_file.txt\n",
    "for filename in $(ls 3.read_mapping/WTS/*.statsfile.txt); do\n",
    "    entry=$(echo ${filename} | sed -e 's/\\(S[0-9].*\\)\\.statsfile.txt/\\1/g' -e 's/.*\\/\\(.*\\)/\\1/g')\n",
    "    if [[ ${entry} == \"S1\"* ]] || [[ ${entry} == \"S2\"* ]]; then\n",
    "        group='water_column_fresh'\n",
    "    elif [[ ${entry} == \"S3\"* ]] || [[ ${entry} == \"S4\"* ]] || [[ ${entry} == \"S5\"* ]] || [[ ${entry} == \"S6\"* ]] || [[ ${entry} == \"S7\"* ]]; then\n",
    "        group='water_column_brackish'\n",
    "    elif [[ ${entry} == \"S8\"* ]] || [[ ${entry} == \"S9\"* ]]; then\n",
    "        group='water_column_marine'\n",
    "    fi\n",
    "    libsize=$(grep 'Reads Used:' ${filename} | sed 's/Reads Used:\\s*\\([0-9]*\\)\\s*.*/\\1/')\n",
    "    echo -e \"${entry}\\t${group}\\t${libsize}\" >> 3.read_mapping/WTS/wts_sample_mapping_file.txt\n",
    "done\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a16a51d-3a51-4834-8a48-2053c012483e",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "#### Run `summarise_counts.py`\n",
    "\n",
    "Note: we can include the sample `genome2contig_lookupTable.tsv` file generated above to also output sums of transcriptional coverage over whole genomes (in contrast to per gene)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e31130-aaa9-45e6-ae16-5a0d866822f3",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Load python and R\n",
    "module purge\n",
    "module load Python/3.8.2-gimkl-2020a\n",
    "module load R-bundle-Bioconductor/3.15-gimkl-2022a-R-4.2.1\n",
    "\n",
    "# Working directory\n",
    "cd /working/dir/3.read_mapping/WTS\n",
    "\n",
    "# Run summarise_counts\n",
    "summarise_counts.py \\\n",
    "    --input '../featureCounts/gene_counts.txt' \\\n",
    "    --sample_mapping_file wts_sample_mapping_file.txt \\\n",
    "    --genome_mapping_file ../genome2contig_lookupTable.tsv \\\n",
    "    --genome_libSize_norm min \\\n",
    "    --format featurecounts \\\n",
    "    --lib_norm total \\\n",
    "    --count_threshold 5 \\\n",
    "    --read_counts wts_summary_read_counts.tsv \\\n",
    "    --edger_out wts_summary_edgeR_glmQLFTest.tsv \\\n",
    "    --output wts_summary_count_table.tsv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457f232f-f288-458c-8159-67d2c18a2c71",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "sos": {
   "kernels": [
    [
     "SoS",
     "sos",
     "",
     ""
    ]
   ],
   "version": "0.23.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
