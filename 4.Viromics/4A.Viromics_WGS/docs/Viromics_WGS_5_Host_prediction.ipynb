{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e139318f-4e2a-491b-8cac-d187e8811749",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Phage host prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52716325-330a-41a1-acb2-e824b046fbca",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18fcf28-ed65-440c-a6bf-0e477bbe96a6",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "While the identification of phage has rapidly increased in the metagenomics age, matching identified phage to their range of host organisms remains a significant limitation of the field. For phage identified in cultured prokaryote isolates or known to infect specific eukaryotic cells, the pairing of phage to host is immediately known (although, the full *range* of posssible hosts may still require further study). In contrast, in the jumbled sea of assembled contigs in a metagenomics study, identifying specific pairings between host (such as prokaryote) genomes and individual viral genomes is a much more complex task. \n",
    "\n",
    "Understanding the host, or range of hosts, that a virus is capable of infecting is vital to understanding viral effects on individual organisms in an ecosystem as well as the dynamics of the ecosystem as a whole. There is also revitalised interest in the use of phage therapy to target \"problematic\" microbes (such as \"pathogenic\" bacteria associated with disease) as an alternative to antibiotics. And while phage discovery is in rapid growth, accurately understanding the range of organisms that many of these phage can infect, and their potential direct effect on those organisms, is currently lagging behind.\n",
    "\n",
    "Several tools and methods have been developed that attempt to address this limitation in viral metagenomics, with the aim of predicting matches between viral genomes and the likely target host that they infect. Some of these include: \n",
    "\n",
    "- machine learning-based approaches *RaFAH*, *HostG*, and *VirHostMatcher*\n",
    "- tRNA pairwise *blast* matching between identified viral tRNA and prokaryote metagenome-assembled genome (MAG) tRNA sequences\n",
    "- nucleotide sequence identity based on pairwise *blast* between viral genomes and full prokaryote MAGs\n",
    "- *blast* matching of CRISPR spacers identified in viral genomes against prokaryote MAGs\n",
    "- identifying integrated prophage genomes contained within larger contigs (including stretches of host genome) that were also binned into specific prokaryote MAGs\n",
    "\n",
    "In practice, several of these approaches (such as the machine learning-based tools) are limited by the fact that reference databases on which they're developed currently still include a small fraction of the likely full viral diversity. We have found that several of the other approaches (such as tRNA blast matching and nucleotide sequence identity) can provide an indication of likely match, but are not difinitive. CRSIPR matching is currently the most robust approach, but in our experience only returns a limited number of hits. Finally, prophage identified directly in binned MAGs have the caveat that differing GC content and coverage (particularly if the virus is replicating at the time) of the viral region within the contig *may* have affected the bin placement, and this contig may not actually correctly belong to the prokaryote MAG that it has been assigned to. Furthermore, each of the latter approaches (CRISPR; tRNA; genome sequence identity) require having available relevant prokaryote references (such as a set of MAGs from the same system (although, in practice these can also be applied to external reference databases as well)). \n",
    "\n",
    "In previous studiees a hierarchy of the reliability of each tool has been applied. And ultimately, concordance of multiple methods is ideal. However, in our experience with complex metagenomics data sets, results from each of these approaches are often contradictory, making interpretation difficult, and much work remains to be done in progressing this field. \n",
    "\n",
    "With these caveats in mind, examples are provided below for several of these approaches (CRISPR spacer matching; viral contigs binned in MAGs; tRNA pairwise blase; genome nucleotide identity), together with some helper scripts to generate easily readable summary tables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc64565-4c59-46e9-8e04-a373084eae0a",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80975ece-acdc-45b3-aa44-cee7a0fa0807",
   "metadata": {
    "tags": []
   },
   "source": [
    "## CRISPR spacer matching\n",
    "\n",
    "This method involves: \n",
    "\n",
    "- identifying and extracting CRISPR spacer sequences in the data set of filtered and trimmed sequencing reads (prior to assembly)\n",
    "- pairwise *blast* searches are then run between: \n",
    "  - spacer sequences vs viral genomes\n",
    "  - spacer sequences vs a set of prokaryote metagenome-assembled genomes. \n",
    "- These results can then be compiled to identify spacer sequences that match between specific viral genomes and specific MAGs.\n",
    "\n",
    "\n",
    "\n",
    "NOTE: \n",
    "\n",
    "- A limitation of this approach is the extent to which the diversity contained within the MAGs data set reflects the full diversity of the system. Often, MAGs are a simplified set of the reality of the system. As such, we might expect to miss a lot of matches due to gaps in the available data.\n",
    "- As some amount of micro-diversity is likely to be lost in the process of dereplicating MAGs (e.g. *dRep* applied to MAGs from multiple assemblies), it may be preferable to apply this step to the set of MAGs *prior* to this dereplication. For example, having refined and reduced MAG sets for each assembly (e.g. via DASTool dereplication of MAGs generated by multiple tools for each assembly, followed by manual curation), but prior to a final dereplication across all assemblies via *dRep*. This is more likely to maximise the microdiversity in the MAG set (which may include some of the sites associated with CRISPR spacers) and may result in an increased number of hits for spacer matches. This will also retain useful information on the specific assemblies (samples, in this case) that particular virus-host CRISPR matches were identified in, and whether they were identified across multiple sites (which may strengthen confidence in the prediction).  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d58262-dfcc-4da9-ae10-ffb103c20c0b",
   "metadata": {},
   "source": [
    "#### Data prep \n",
    "\n",
    "Concatenate prokaryote MAGs, and also copy over read files\n",
    "\n",
    "NOTE: \n",
    "\n",
    "- In some cases it is necessary to filter out problematic reads that cause *crass* to crash (the output names the reads that are the issue). To enable modifying the reads files without affecting the original set, copy over read files first, then filter, then (re)run *crass*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abbf602-a280-4843-ba7d-47987bd85b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# working directory\n",
    "cd /working/dir\n",
    "\n",
    "# Concatenate bins into all.hosts.fna\n",
    "mkdir -p 5.host_prediction/crispr/bins\n",
    "cat /path/to/bin_files/*.fa > 5.host_prediction/crispr/bins/all.hosts.fna\n",
    "\n",
    "# Copy over reads files\n",
    "mkdir -p 5.host_prediction/crispr/infiles\n",
    "cp /path/to/wgs/1.Qual_filtered_trimmomatic/*.fastq 5.host_prediction/crispr/infiles/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a90169e-cdd2-447b-9836-cda645506d44",
   "metadata": {},
   "source": [
    "If required: remove problematic reads\n",
    "\n",
    "After a first pass of *crass* (see below), if any runs crashed due to problematic reads these can be filtered out here and then *crass* re-run.\n",
    "\n",
    "Example where multiple reads from S8 and S9 failed: \n",
    "\n",
    "- `sed` here identifies the header row based on ID and deletes this row and the 3 that follow (since sequences cover four lines in *fastq* file format). \n",
    "- Note that the read IDs for R1 and R2 will be identical except for the `1` or `2` at the start of the section after the space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69d7a98-a9eb-47a7-867b-dc95c92ec3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH -A your_project_account\n",
    "#SBATCH -J 7_crispr_prep\n",
    "#SBATCH --time 02:00:00\n",
    "#SBATCH --mem 100MB\n",
    "#SBATCH --ntasks 1\n",
    "#SBATCH --cpus-per-task 2\n",
    "#SBATCH -e 7_crispr_prep.err\n",
    "#SBATCH -o 7_crispr_prep.out\n",
    "\n",
    "# working directory\n",
    "cd /working/dir/5.host_prediction/crispr/infiles\n",
    "\n",
    "## Remove problematic reads\n",
    "\n",
    "# S8_R1 problem read 1\n",
    "sed -i '/^@7001326F:173:H27CLBCX3:1:2114:12778:70365 1:N:0:ATTCAGAA+GTACTGAC/,+3d' S8_R1.fastq\n",
    "sed -i '/^@7001326F:173:H27CLBCX3:1:2114:12778:70365 2:N:0:ATTCAGAA+GTACTGAC/,+3d' S8_R2.fastq\n",
    "\n",
    "# S8_R1 problem read 2\n",
    "sed -i '/^@7001326F:172:H27C7BCX3:1:1211:9175:92520 1:N:0:ATTCAGAA+GTACTGAC/,+3d' S8_R1.fastq\n",
    "sed -i '/^@7001326F:172:H27C7BCX3:1:1211:9175:92520 2:N:0:ATTCAGAA+GTACTGAC/,+3d' S8_R2.fastq\n",
    "\n",
    "# S8_R1 problem read 3\n",
    "sed -i '/^@7001326F:173:H27CLBCX3:1:2213:15674:2212 1:N:0:ATTCAGAA+GTACTGAC/,+3d' S8_R1.fastq\n",
    "sed -i '/^@7001326F:173:H27CLBCX3:1:2213:15674:2212 2:N:0:ATTCAGAA+GTACTGAC/,+3d' S8_R2.fastq\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658f54f8-10b3-4d86-a621-691d44eb65d7",
   "metadata": {},
   "source": [
    "#### Extract crispr spacers\n",
    "\n",
    "1. Identify CRISPR spacer sequences from filtered sequencing reads via *crass*\n",
    "1. get stats via `crisprtools stat` (part of *crass* install)\n",
    "1. Extract spacer sequences\n",
    "1. Add sample info into headers of spacer sequences\n",
    "\n",
    "NOTE:\n",
    "\n",
    "- *crass* is not currently available as a NeSI module. You will need to download this first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9df9ea4-3624-4f03-a60f-263187a7ef40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH -A your_project_account\n",
    "#SBATCH -J 7_crispr_crass\n",
    "#SBATCH --time 06:00:00\n",
    "#SBATCH --mem 3GB\n",
    "#SBATCH --ntasks 1\n",
    "#SBATCH --array=1-9\n",
    "#SBATCH --cpus-per-task 2\n",
    "#SBATCH -e 7_crispr_crass_%a.err\n",
    "#SBATCH -o 7_crispr_crass_%a.out\n",
    "\n",
    "# working directory\n",
    "cd /working/dir/5.host_prediction\n",
    "\n",
    "# Paths\n",
    "crass_path=/nesi/project/uoa02469/Software/crass/bin\n",
    "\n",
    "# run crass\n",
    "mkdir -p crispr/S${SLURM_ARRAY_TASK_ID}\n",
    "\n",
    "${crass_path}/crass \\\n",
    "crispr/infiles/S${SLURM_ARRAY_TASK_ID}_R1.fastq \\\n",
    "crispr/infiles/S${SLURM_ARRAY_TASK_ID}_R2.fastq \\\n",
    "-o crispr/S${SLURM_ARRAY_TASK_ID}/\n",
    "\n",
    "# Get stats via crisprtools stats\n",
    "mkdir -p crispr/stats_out\n",
    "\n",
    "${crass_path}/crisprtools stat \\\n",
    "-ap crispr/S${SLURM_ARRAY_TASK_ID}/crass.crispr \\\n",
    "> crispr/stats_out/S${SLURM_ARRAY_TASK_ID}_crass_stats.txt\n",
    "\n",
    "# Extract spacer sequences\n",
    "mkdir -p crispr/spacer_seqs\n",
    "\n",
    "${crass_path}/crisprtools extract \\\n",
    "-o crispr/ -O crispr/S${SLURM_ARRAY_TASK_ID}/ \\\n",
    "-s crispr/S${SLURM_ARRAY_TASK_ID}/crass.crispr \\\n",
    "> crispr/spacer_seqs/S${SLURM_ARRAY_TASK_ID}_spacers.fa\n",
    "\n",
    "# Add sample info to sequence headers of spacers.fa files\n",
    "sed -i \"s/>/>S${SLURM_ARRAY_TASK_ID}_/g\" crispr/spacer_seqs/S${SLURM_ARRAY_TASK_ID}_spacers.fa\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b756ea-1086-4fb2-b9c0-71f639e84363",
   "metadata": {},
   "source": [
    "#### *Blastn*: spacers vs viral contigs and MAGs\n",
    "\n",
    "Run blast comparison between spacers and vOTUs and bins\n",
    "\n",
    "NOTE: The associated helper script to generate summary tables *requires* that `-outfmt` be set exactly as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3315e9ef-5d13-4929-ac2a-f586c653d92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# working directory\n",
    "cd /working/dir/5.host_prediction/\n",
    "mkdir -p crispr/spacers_blastn\n",
    "\n",
    "# load blast\n",
    "module purge\n",
    "module load BLAST/2.9.0-gimkl-2018b\n",
    "\n",
    "## Concatenate spacers together\n",
    "cat crispr/spacer_seqs/*.fa > crispr/spacer_seqs/all_spacer_seqs.fna\n",
    "\n",
    "## Build index\n",
    "makeblastdb -in crispr/spacer_seqs/all_spacer_seqs.fna -dbtype nucl \\\n",
    "-out crispr/spacer_seqs/all_spacer_seqs.fna\n",
    "\n",
    "## Bins\n",
    "# working directory\n",
    "cd /working/dir/5.host_prediction/\n",
    "# Run blastn vs bins\n",
    "blastn -num_threads 6 \\\n",
    "-query crispr/bins/all.hosts.fna \\\n",
    "-db crispr/spacer_seqs/all_spacer_seqs.fna \\\n",
    "-outfmt \"6 qseqid qlen sseqid slen pident length mismatch gapopen qstart qend sstart send evalue bitscore qcovs\" \\\n",
    "-out crispr/spacers_blastn/blastn_crisprSpacers.Bins.txt\n",
    "\n",
    "## vOTUs\n",
    "# working directory\n",
    "cd /working/dir/5.host_prediction/\n",
    "# Run blastn vs viral contigs\n",
    "blastn -num_threads 6 \\\n",
    "-query ../6.checkv_vOTUs/vOTUs.checkv_filtered.fna \\\n",
    "-db crispr/spacer_seqs/all_spacer_seqs.fna \\\n",
    "-outfmt \"6 qseqid qlen sseqid slen pident length mismatch gapopen qstart qend sstart send evalue bitscore qcovs\" \\\n",
    "-out crispr/spacers_blastn/blastn_crisprSpacers.vOTUs.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aff9053-2b02-4100-834b-1829d41bf6a9",
   "metadata": {},
   "source": [
    "#### Compile crispr spacers summary results table\n",
    "\n",
    "NOTE: \n",
    "\n",
    "- `n_hits_threshold` at the beginning sets the number of top matches to keep for each blast search\n",
    "- The script below *requires* that `-outfmt` be set exactly as above when running the blast searches.\n",
    "- This script includes filtering to keep only blast matches with ≤ 1 mismatch over the full length of the spacer sequence\n",
    "- This script also includes adding gtdb predicted MAG taxonomy for each of the matching bins (if this is unavailable, it is useful to run this first, or modify the script below to remove gtdb-related steps)\n",
    "- This will ultimately be put into a script for ease of use. But for now we can use the python code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f3fb33-1a31-4683-bf15-fc8f8d3dea7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# working directory\n",
    "cd /working/dir/5.host_prediction\n",
    "mkdir -p summary_tables\n",
    "\n",
    "# Load python\n",
    "module purge\n",
    "module load Python/3.8.2-gimkl-2020a\n",
    "python3\n",
    "\n",
    "### Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import glob\n",
    "\n",
    "## number of top hits to keep\n",
    "n_hits_threshold = 3\n",
    "\n",
    "## File paths\n",
    "gtdb_taxonomy_path = '/path/to/gtdb/output'\n",
    "crispr_results_bins = 'crispr/spacers_blastn/blastn_crisprSpacers.Bins.txt'\n",
    "crispr_results_votus = 'crispr/spacers_blastn/blastn_crisprSpacers.vOTUs.txt'\n",
    "\n",
    "## GTDB\n",
    "# Read in gtdb taxonomy to append to each\n",
    "gtdb_df = pd.concat([pd.read_csv(f, sep='\\t') for f in glob.glob(\"/path/to/gtdb/output/*.summary.tsv\")],\n",
    "                      ignore_index=True)[['user_genome', 'classification']]\n",
    "gtdb_df.columns = ['crispr_blast_binID', 'crispr_blast_bin_taxonomy_gtdb']\n",
    "\n",
    "## Bins results\n",
    "# Read in blast results\n",
    "bins_df = pd.read_csv(crispr_results_bins, sep='\\t', header=None)\n",
    "# Rename columns\n",
    "bins_df.columns = ['bin_contig_ID', 'query_length', 'spacer_ID', 'spacer_len', 'pident', 'match_length', 'mismatch', 'gapopen', 'query_start', 'query_end', 'spacer_start', 'spacer_end', 'evalue', 'bitscore', 'query_covs']\n",
    "# Filter to only keep matches with ≤ 1 mismatch over the full length of the spacer sequence\n",
    "bins_df = bins_df[(bins_df['spacer_len'] == bins_df['match_length']) & (bins_df['mismatch'] <= 1)]\n",
    "\n",
    "## vOTUs\n",
    "# Read in blast results\n",
    "df = pd.read_csv(crispr_results_votus, sep='\\t', header=None)\n",
    "# Rename columns\n",
    "df.columns = ['virID', 'query_length', 'spacer_ID', 'spacer_len', 'pident', 'match_length', 'mismatch', 'gapopen', 'query_start', 'query_end', 'spacer_start', 'spacer_end', 'evalue', 'bitscore', 'query_covs']\n",
    "# Filter to only keep matches with ≤ 1 mismatch over the full length of the spacer sequence\n",
    "df = df[(df['spacer_len'] == df['match_length']) & (df['mismatch'] <= 1)]\n",
    "# join with bins results (by spacer_ID) and filter to keep only rows that have hits for both a viral contig and a binned contig\n",
    "df = pd.merge(df, bins_df, how=\"left\", on=\"spacer_ID\", suffixes=(\"_vir\", \"_bin\"))\n",
    "df = df[df['bin_contig_ID'].notnull()].sort_values(by=['virID'])\n",
    "# Add gtdb taxonomy for bins\n",
    "df['crispr_blast_binID'] = df['bin_contig_ID'].str.replace(r'_NODE.*', '')\n",
    "df = pd.merge(df, gtdb_df, how=\"left\", on=\"crispr_blast_binID\").reset_index(drop=True)\n",
    "# Filter to keep columns of interest\n",
    "df = df[['virID', 'pident_vir', 'evalue_vir', 'bitscore_vir', 'pident_bin', 'evalue_bin', 'bitscore_bin', 'crispr_blast_binID', 'crispr_blast_bin_taxonomy_gtdb']]\n",
    "df.columns = ['virID', 'crispr_blast_pident_vir', 'crispr_blast_evalue_vir', 'crispr_blast_bitscore_vir', 'crispr_blast_pident_bin', 'crispr_blast_evalue_bin', 'crispr_blast_bitscore_bin', 'crispr_blast_binID', 'crispr_blast_bin_taxonomy_gtdb']\n",
    "\n",
    "## filter to only keep top n hits for each vOTU_ID\n",
    "# ERROR handling: If n_hits_threshold greater than or equal to max counts, need to modify n_hits_threshold\n",
    "MAX_VALUE_COUNTS = df.groupby('virID')['virID'].value_counts().max()\n",
    "if n_hits_threshold >= MAX_VALUE_COUNTS:\n",
    "    n_hits_threshold_edit = MAX_VALUE_COUNTS-1\n",
    "else:\n",
    "    n_hits_threshold_edit = n_hits_threshold\n",
    "\n",
    "# filter by n_hits_threshold\n",
    "df = df[df.index.isin(df.groupby('virID')['crispr_blast_evalue_vir'].nsmallest(n_hits_threshold_edit).index.get_level_values(1))].sort_values(by=['virID', 'crispr_blast_evalue_vir'])\n",
    "# pivot wider and apply suffix to multiple hits\n",
    "df['idx'] = '_'+(df.groupby(['virID']).cumcount() + 1).astype(str)\n",
    "df = (\n",
    "    df.pivot_table(\n",
    "        index=['virID'], \n",
    "        columns=['idx'], \n",
    "        values=['crispr_blast_pident_vir', 'crispr_blast_evalue_vir', 'crispr_blast_bitscore_vir', 'crispr_blast_pident_bin', 'crispr_blast_evalue_bin', 'crispr_blast_bitscore_bin', 'crispr_blast_binID', 'crispr_blast_bin_taxonomy_gtdb'], \n",
    "        aggfunc='first'\n",
    "    )\n",
    ")\n",
    "df.columns = [''.join(col) for col in df.columns]\n",
    "df = df.reset_index()\n",
    "\n",
    "## Write out summary table\n",
    "df.to_csv('summary_tables/summary_table.crisprSpacers_blastn.tsv', sep='\\t', index=False)\n",
    "\n",
    "quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66508d20-2b29-42c6-8bc2-68b9dbc2b7e9",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2d4957-31b8-4f1d-8f39-7561a5a4c76b",
   "metadata": {},
   "source": [
    "## Binned viral contigs\n",
    "\n",
    "- Identify any viral contigs that were co-binned when generating the Prokaryote MAGs data set.\n",
    "- Note that this requires a bin2contig_lookupTable matching contigIDs of all contigs binned into MAGs against their MAG (bin) ID (two columns, with headers `contigID` and `binID`). See **VirusStudies_WGS_5_Read_mapping** for more information and some python code to generate this table.\n",
    "- The `vOTUs_lookupTable.txt` was originally generated during dereplication of viral contigs into vOTUs back in **VirusStudies_WGS_3_Viral_Identification**.\n",
    "- *Optional*: The script below also incorporates MAG taxonomy (gtdb results) and checkM, as these are useful metrics to include here.\n",
    "- This will ultimately be put into a script for ease of use. But for now we can use the python code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0b79e1-3f01-41a4-9b5c-4e327632bbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# working directory\n",
    "cd /working/dir\n",
    "mkdir -p 5.host_prediction/binned_contigs/\n",
    "mkdir -p 5.host_prediction/summary_tables\n",
    "\n",
    "# Load python\n",
    "module purge\n",
    "module load Python/3.8.2-gimkl-2020a\n",
    "python3\n",
    "\n",
    "### Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from Bio.SeqIO.FastaIO import SimpleFastaParser\n",
    "import os\n",
    "\n",
    "# File paths\n",
    "votus_lookupTable_path = '1.viral_identification/5.cluster_vOTUs/vOTUs_lookupTable.txt'\n",
    "viral_contigs_path = '1.viral_identification/6.checkv_vOTUs/vOTUs.checkv_filtered.fna'\n",
    "MAGs_bin2contig_lookupTable_path = '/path/to/MAGs_bin2contig_lookupTable.tsv'\n",
    "MAGs_checkM_summary_path = '/path/to/checkm_bin_summary.txt'\n",
    "MAGS_gtdb_output_path = '/path/to/gtdb/output'\n",
    "\n",
    "# vOTUs\n",
    "votus_dict = {}\n",
    "with open(viral_contigs_path, 'r') as read_fasta:\n",
    "    for name, seq in SimpleFastaParser(read_fasta):\n",
    "        votus_dict[name] = seq\n",
    "\n",
    "# Convert to dataframe\n",
    "votu_df = pd.DataFrame.from_dict(votus_dict.items())\n",
    "votu_df.columns = ['vOTU_ID_full', 'seq']\n",
    "votu_df['vOTU_ID'] = votu_df['vOTU_ID_full'].str.replace(r'(vOTU_\\d+).*', r'\\1', regex=True)\n",
    "\n",
    "# Join with lookuptable to get original contigIDs\n",
    "lookupTable_df = pd.read_csv(votus_lookupTable_path, sep='\\t')\n",
    "# Trim contigID back to orignal form\n",
    "lookupTable_df['contigID'] = lookupTable_df['cluster_rep_contigID'].str.replace(r'(cov_.*\\.\\d+).*', r'\\1', regex=True)\n",
    "votu_df = pd.merge(votu_df, lookupTable_df, left_on=\"vOTU_ID\", right_on=\"vOTU\", how=\"left\")\n",
    "\n",
    "# join with MAGs bin2contig lookupTable to identify any matches between the datasets\n",
    "mag_bin2contig_df = pd.read_csv(MAGs_bin2contig_lookupTable_path, sep='\\t')\n",
    "votu_df = pd.merge(votu_df, mag_bin2contig_df, on=\"contigID\", how=\"left\")\n",
    "\n",
    "# binned vOTU contigs (exclude any rows with no matches between vOTUs and MAGs)\n",
    "binned_votus_df = votu_df[~votu_df['binID'].isna()]\n",
    "\n",
    "# For reference: Counts of binIDs with vOTU matches (Open to view)\n",
    "vir2bin_matches_df = binned_votus_df['binID'].value_counts().rename_axis('bins').reset_index(name='counts')\n",
    "\n",
    "# Write out results table\n",
    "binned_votus_df = binned_votus_df[['vOTU_ID_full', 'binID']]\n",
    "binned_votus_df.columns = ['virID', 'cobinned_binID']\n",
    "binned_votus_df.to_csv('5.host_prediction/binned_contigs/vOTUs.cobinned.tsv', sep='\\t', index=False)\n",
    "\n",
    "# Optional: read in MAG taxonomy (gtdb) and checkM and join with cobinned results\n",
    "gtdb_df = pd.concat([pd.read_csv(f, sep='\\t') for f in glob.glob(MAGS_gtdb_output_path+\"/*.summary.tsv\")],\n",
    "                      ignore_index=True)[['user_genome', 'classification']]\n",
    "gtdb_df.columns = ['binID', 'cobinned_bin_taxonomy_gtdb']\n",
    "checkm_df = pd.read_csv(MAGs_checkM_summary_path, sep='\\t')[['Bin Id', 'Completeness', 'Contamination', 'Strain heterogeneity']]\n",
    "checkm_df.columns = ['binID', 'cobinned_checkm_Completeness', 'cobinned_checkm_Contamination', 'cobinned_checkm_Strain heterogeneity']\n",
    "mag_stats_df = pd.merge(gtdb_df, checkm_df, how=\"outer\", on=\"binID\").reset_index(drop=True).rename(columns={\"binID\": \"cobinned_binID\"})\n",
    "# Join MAG stats with cobinned results\n",
    "full_df = pd.merge(binned_votus_df, mag_stats_df, how=\"left\", left_on=\"cobinned_binID\", right_on=\"cobinned_binID\").reset_index(drop=True)\n",
    "\n",
    "# Write out summary table\n",
    "full_df.to_csv('5.host_prediction/summary_tables/summary_table.vir_contigs.cobinned.tsv', sep='\\t', index=False)\n",
    "\n",
    "quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893b97bc-fa00-47d7-b9aa-3a59e283b5c4",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381ef088-523c-41da-a570-2afeb4bff055",
   "metadata": {},
   "source": [
    "## tRNA pairwise *blast*\n",
    "\n",
    "Pairwise blast comparison of tRNA sequences predicted from bin (MAG) files and viral contigs\n",
    "\n",
    "NOTE:\n",
    "\n",
    "- (As with CRISPR matching above), as some amount of micro-diversity is likely to be lost in the process of dereplicating MAGs (e.g. *dRep* applied to MAGs from multiple assemblies), it may be preferable to apply this step to the set of MAGs *prior* to this dereplication. This is more likely to maximise the microdiversity in the MAG set (and potentailly the diversity of tRNA) and may result in an increased number of hits for tRNA matches. This will also retain useful information on the specific assemblies (samples, in this case) that particular tRNA matches were identified in, and whether they were identified across multiple sites (which may strengthen confidence in the prediction).\n",
    "- *aragorn* is not currently available as a NeSI module. You will need to download and install this first.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0abc8d-814e-425b-8a22-070bfb512259",
   "metadata": {},
   "source": [
    "#### Set up working directory and copy infiles over\n",
    "\n",
    "NOTE:\n",
    "\n",
    "- In the next step, we will predict tRNA sequences for each individual \"genome\" via *aragorn*. Here we will first generate individual files for each \"genome\" (contig) in the vOTUs data set. A simple python script to achieve this is given below.\n",
    "- If your bin (MAG) file extensions are something other than `.fa` (e.g. `.fna`), ammend the script below in both the bin files copy step *and* the step writing out the individual viral contig files (so that all extensions match for ease of use downstream), and *also* in the subsequent *aragorn* step below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d746b374-00b9-430c-be5b-03f0eb2be10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /working/dir\n",
    "\n",
    "# Make output directories\n",
    "mkdir -p 5.host_prediction/tRNA_blast/infiles\n",
    "\n",
    "## bin files \n",
    "cp /path/to/bin_files/*.fa 5.host_prediction/tRNA_blast/infiles/\n",
    "\n",
    "## Viral contigs\n",
    "# Split virus fasta file into individual sequences\n",
    "# Load python\n",
    "module purge\n",
    "module load Python/3.8.2-gimkl-2020a\n",
    "python3\n",
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Bio.SeqIO.FastaIO import SimpleFastaParser\n",
    "# Write individual fasta files\n",
    "with open('1.viral_identification/6.checkv_vOTUs/vOTUs.checkv_filtered.fna', 'r') as read_fasta:\n",
    "    for name, seq in SimpleFastaParser(read_fasta):\n",
    "        with open('5.host_prediction/tRNA_blast/infiles/'+name+'.fa', 'w') as write_fasta:\n",
    "            write_fasta.write(\">\" + str(name) + \"\\n\" + str(seq) + \"\\n\")\n",
    "\n",
    "quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f5e4d5-77ca-42d0-838f-84c7d3ff1ed0",
   "metadata": {},
   "source": [
    "#### Identify tRNA\n",
    "\n",
    "Run *aragorn* on each \"genome\" and prep for pairwise *blast*\n",
    "\n",
    "Note: \n",
    "\n",
    "- The prep steps include: Removing any empty files (i.e. those with no predicted tRNAs); Modifying contig headers in aragorn output files (to simplify downstream use); Concatenating viral tRNAs and host tRNAs in two files.\n",
    "- The concatenation step for tRNA files relating to MAGs is currently written based on naming generated by metabat, maxbin, and concoct. If this does not match your MAG file names, ammend this line in the code below (e.g. if your MAG files are all simply labelled \"MAG_n.fna\" then  `cat MAG_*.trna.fna >  concatenated_tRNA/host_tRNA.fna` will suffice)\n",
    "- *aragorn* is not currently available as a NeSI module. You will need to download and install this first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6374c67d-f3bd-4943-8f14-7169e5ca06e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash -e\n",
    "#SBATCH -A your_project_account\n",
    "#SBATCH -J 7_tRNA_aragorn\n",
    "#SBATCH --time 03:00:00\n",
    "#SBATCH --mem=1GB\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --cpus-per-task=12\n",
    "#SBATCH -e 7_tRNA_aragorn.err\n",
    "#SBATCH -o 7_tRNA_aragorn.out\n",
    "#SBATCH --profile=task\n",
    "\n",
    "# load dependencies\n",
    "module purge\n",
    "\n",
    "# Working dir\n",
    "mkdir -p /working/dir/5.host_prediction/tRNA_blast/aragorn_out\n",
    "cd /working/dir/5.host_prediction/tRNA_blast\n",
    "\n",
    "## Run Aragorn\n",
    "for file in infiles/*.fa; do \n",
    "    filename=$(basename ${file} .fa)\n",
    "    /path/to/Software/aragorn_v1.2.38/aragorn \\\n",
    "    -t -gcstd -l -a -q -rn -fon \\\n",
    "    -o aragorn_out/${filename}.aragorn \\\n",
    "    ${file}\n",
    "done\n",
    "\n",
    "## Prep for pairwise blast\n",
    "cd aragorn_out/\n",
    "\n",
    "# Remove empty files\n",
    "find . -type f -empty -delete\n",
    "# modify contig headers\n",
    "for file in *aragorn; do \n",
    "    filename=$(basename ${file} .aragorn)\n",
    "    sed -e \"s/>/>${filename}_/g\" -e 's/\\(.*\\) .*/\\1/' -e 's/[^a-zA-Z0-9>]/_/g' -e 's/_$//g' ${file} > ${file}.trna.fna\n",
    "done\n",
    "\n",
    "# concatenate into viral_tRNA.fna and host_tRNA.fna\n",
    "mkdir -p concatenated_tRNA\n",
    "cat vOTU*.trna.fna > concatenated_tRNA/viral_tRNA.fna\n",
    "cat *metabat*.trna.fna *maxbin*.trna.fna *concoct*.trna.fna > concatenated_tRNA/host_tRNA.fna\n",
    "\n",
    "# Compile tRNA with aragorn headers in full (i.e. the original aragorn output files, rather than those with modified contig headers)\n",
    "mkdir -p concatenated_tRNA_aragorn\n",
    "cat vOTU*.aragorn > concatenated_tRNA_aragorn/viral_tRNA.fna\n",
    "cat *metabat*.aragorn *maxbin*.aragorn *concoct*.aragorn > concatenated_tRNA_aragorn/host_tRNA.fna\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835bfc81-6ade-439a-a29d-31f7560ee415",
   "metadata": {},
   "source": [
    "#### Pairwise blast of tRNA sequences\n",
    "\n",
    "NOTE:\n",
    "\n",
    "- `-outfmt` must be exactly as below for the subsequent script that generates the summary table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881c7794-c5eb-4231-ae5f-0a57eb2121cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load module(s)\n",
    "module purge\n",
    "module load BLAST/2.9.0-gimkl-2018b\n",
    "\n",
    "# Working dir\n",
    "cd /working/dir/5.host_prediction/tRNA_blast\n",
    "\n",
    "# blast db of host_tRNA.fna\n",
    "makeblastdb -in aragorn_out/concatenated_tRNA/host_tRNA.fna -dbtype nucl \\\n",
    "-out aragorn_out/concatenated_tRNA/host_tRNA.fna\n",
    "\n",
    "# Pairwise blast of viral_tRNA v. host_tRNA\n",
    "blastn \\\n",
    "-query aragorn_out/concatenated_tRNA/viral_tRNA.fna \\\n",
    "-db aragorn_out/concatenated_tRNA/host_tRNA.fna \\\n",
    "-num_threads 8 \\\n",
    "-outfmt \"6 qseqid qlen sseqid slen pident length mismatch gapopen qstart qend sstart send evalue bitscore qcovs\" \\\n",
    "-num_alignments 5 \\\n",
    "-perc_identity 90 -dust no \\\n",
    "-out vOTUs.tRNA_blast_virus_host.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8076e0-85be-44af-97ec-33a6ba150321",
   "metadata": {},
   "source": [
    "#### Compile tRNA blast filtered summary results table\n",
    "\n",
    "NOTE: \n",
    "\n",
    "- `n_hits_threshold` at the beginning sets the number of top matches to keep for each blast search\n",
    "- The script below *requires* that `-outfmt` be set exactly as above when running the blast search.\n",
    "- This script includes a filtering step to keep only blast matches with ≥ 90% nucleotide identity over ≥ 90% length of sequence\n",
    "- This script also includes adding gtdb predicted MAG taxonomy for each of the matching bins (if this is unavailable, it is useful to run this first, or modify the script below to remove gtdb-related steps)\n",
    "- This will ultimately be put into a script for ease of use. But for now we can use the python code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d60849-a2e4-40e4-a1fa-47d515dde5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# working directory\n",
    "cd /working/dir/5.host_prediction\n",
    "mkdir -p summary_tables\n",
    "\n",
    "# Load python\n",
    "module purge\n",
    "module load Python/3.8.2-gimkl-2020a\n",
    "python3\n",
    "\n",
    "### Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import glob\n",
    "\n",
    "### keep n hit threshold setting\n",
    "n_hits_threshold = 3\n",
    "\n",
    "## File paths\n",
    "gtdb_taxonomy_path = '/path/to/gtdb/output'\n",
    "trna_blast_path = 'tRNA_blast/vOTUs.tRNA_blast_virus_host.txt'\n",
    "\n",
    "## Read in gtdb taxonomy to append to each\n",
    "gtdb_df = pd.concat([pd.read_csv(f, sep='\\t') for f in glob.glob(gtdb_taxonomy_path+\"/*.summary.tsv\")],\n",
    "                      ignore_index=True)[['user_genome', 'classification']]\n",
    "gtdb_df.columns = ['tRNA_blast_binID', 'tRNA_blast_bin_taxonomy_gtdb']\n",
    "\n",
    "## Read in and process blast results\n",
    "df = pd.read_csv(trna_blast_path', sep='\\t', header=None)\n",
    "# Rename columns\n",
    "df.columns = ['vir_tRNA_ID', 'vir_tRNA_length', 'bin_tRNA_ID', 'bin_tRNA_len', 'pident', 'match_length', 'mismatch', 'gapopen', 'vir_tRNA_start', 'vir_tRNA_end', 'bin_tRNA_start', 'bin_tRNA_end', 'evalue', 'bitscore', 'vir_covs']\n",
    "# Add virID column\n",
    "df['virID'] = df['vir_tRNA_ID'].str.replace(r'(vOTU_.*)_.*_.*_tRNA.*', r'\\1')\n",
    "# Add % length of sequence match\n",
    "df['match_length_pct'] = ((df['match_length'] / df[[\"vir_tRNA_length\", \"bin_tRNA_len\"]].min(axis=1))*100).round(2)\n",
    "# Filter to only keep matches with ≥ 90% nucleotide identity and ≥ 90% length of (shortest) tRNA sequence\n",
    "df = df[(df['pident'] >= 90) & (df['match_length_pct'] >= 90)]\n",
    "# Add gtdb taxonomy for bins\n",
    "df['tRNA_blast_binID'] = df['bin_tRNA_ID'].str.replace(r'(contigs).*', r'\\1').str.replace(r'_', r'.').str.replace(r'.sub', r'_sub')\n",
    "df = pd.merge(df, gtdb_df, how=\"left\", on=\"tRNA_blast_binID\").reset_index(drop=True)\n",
    "# Filter to keep columns of interest\n",
    "df = df[['virID', 'tRNA_blast_binID', 'tRNA_blast_bin_taxonomy_gtdb', 'pident', 'evalue', 'bitscore']]\n",
    "df.columns = ['virID', 'tRNA_blast_binID', 'tRNA_blast_bin_taxonomy_gtdb', 'tRNA_blast_pident', 'tRNA_blast_evalue', 'tRNA_blast_bitscore']\n",
    "\n",
    "## filter to only keep top n hits for each vOTU_ID\n",
    "# ERROR handling: If n_hits_threshold greater than or equal to max counts, need to modify n_hits_threshold\n",
    "MAX_VALUE_COUNTS = df.groupby('virID')['virID'].value_counts().max()\n",
    "if n_hits_threshold >= MAX_VALUE_COUNTS:\n",
    "    n_hits_threshold_edit = MAX_VALUE_COUNTS-1\n",
    "else:\n",
    "    n_hits_threshold_edit = n_hits_threshold\n",
    "\n",
    "# Filter based on n_hits_threshold\n",
    "df = df[df.index.isin(df.groupby('virID')['tRNA_blast_evalue'].nsmallest(n_hits_threshold_edit).index.get_level_values(1))].sort_values(by=['virID', 'tRNA_blast_evalue'])\n",
    "# pivot wider and apply suffix to multiple hits\n",
    "df['idx'] = '_'+(df.groupby(['virID']).cumcount() + 1).astype(str)\n",
    "df = (df.pivot_table(index=['virID'], \n",
    "                               columns=['idx'], \n",
    "                               values=['tRNA_blast_binID', 'tRNA_blast_bin_taxonomy_gtdb', 'tRNA_blast_pident', 'tRNA_blast_evalue', 'tRNA_blast_bitscore'], \n",
    "                               aggfunc='first'))\n",
    "df.columns = [''.join(col) for col in df.columns]\n",
    "df = df.reset_index()\n",
    "\n",
    "## Write out summary table\n",
    "df.to_csv('summary_tables/summary_table.tRNA_blast_virus_host.tsv', sep='\\t', index=False)\n",
    "\n",
    "quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437d35c0-b115-4477-bbe5-d48fad260254",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5963236e-cd4a-449e-8870-cbe505660115",
   "metadata": {},
   "source": [
    "## Whole genome nucleotide sequence identity\n",
    "\n",
    "Run pairwise *blast* searches between vOTUs and MAGs to assess whole genome sequence identity\n",
    "\n",
    "NOTE:\n",
    "\n",
    "- (As with CRISPR spacer and tRNA matching above), as some amount of micro-diversity is likely to be lost in the process of dereplicating MAGs (e.g. *dRep* applied to MAGs from multiple assemblies), it may be preferable to apply this step to the set of MAGs *prior* to this dereplication. This is more likely to maximise the microdiversity in the MAG set (and potentailly the diversity of tRNA) and may result in an increased number of hits for tRNA matches. This will also retain useful information on the specific assemblies (samples, in this case) that particular tRNA matches were identified in, and whether they were identified across multiple sites (which may strengthen confidence in the prediction).\n",
    "- `-outfmt` must be exactly as below for the subsequent script that generates the summary table.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207d3414-3e55-4fd0-94b5-c80a8dc186e7",
   "metadata": {},
   "source": [
    "#### Prep infiles and run *blast*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857098de-3111-4532-800d-c414b4c401e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working directory\n",
    "cd /working/dir\n",
    "\n",
    "# Concatenate bins into all.hosts.fna\n",
    "mkdir -p 5.host_prediction/pairwise_blast/infiles\n",
    "cat /path/to/bin_files/*.fa > 5.host_prediction/pairwise_blast/infiles/all.hosts.fna\n",
    "\n",
    "# load blast\n",
    "module purge\n",
    "module load BLAST/2.9.0-gimkl-2018b\n",
    "\n",
    "# Generate database from all.hosts.fna\n",
    "makeblastdb \\\n",
    "-in 5.host_prediction/pairwise_blast/infiles/all.hosts.fna -dbtype nucl \\\n",
    "-out 5.host_prediction/pairwise_blast/infiles/all.hosts.fna\n",
    "\n",
    "# Pairwise blast against vOTUs (blast pairwise comparisons based on nucleotide sequence identity)\n",
    "blastn -num_threads 10 \\\n",
    "-query 1.viral_identification/6.checkv_vOTUs/vOTUs.checkv_filtered.fna \\\n",
    "-db 5.host_prediction/pairwise_blast/infiles/all.hosts.fna \\\n",
    "-outfmt \"6 qseqid qlen sseqid slen pident length mismatch gapopen qstart qend sstart send evalue bitscore qcovs\" \\\n",
    "-perc_identity 70 \\\n",
    "-out 5.host_prediction/pairwise_blast/vOTUs.pairwise_blast.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be989b53-0c5c-4210-96f4-2cb5d3e9b8b7",
   "metadata": {},
   "source": [
    "#### Compile filtered summary results tables\n",
    "\n",
    "NOTE:\n",
    "\n",
    "- `n_hits_threshold` at the beginning sets the number of top matches to keep for each blast search\n",
    "- The script below *requires* that `-outfmt` be set exactly as above when running the blast search.\n",
    "- This script includes a filtering step to keep only blast matches with: e-value ≤ 0.001; nucleotide identity ≥ 70%; bit-score ≥ 50\n",
    "- This script also includes adding gtdb predicted MAG taxonomy for each of the matching bins (if this is unavailable, it is useful to run this first, or modify the script below to remove gtdb-related steps)\n",
    "- This will ultimately be put into a script for ease of use. But for now we can use the python code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2bbb3a-36a6-404e-bd17-5b680dc1b4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# working directory\n",
    "cd /working/dir/5.host_prediction\n",
    "mkdir -p summary_tables\n",
    "\n",
    "# Load python\n",
    "module purge\n",
    "module load Python/3.8.2-gimkl-2020a\n",
    "python3\n",
    "\n",
    "### Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import glob\n",
    "\n",
    "### number of top hits to keep\n",
    "n_hits_threshold = 3\n",
    "\n",
    "## File paths\n",
    "gtdb_taxonomy_path = '/path/to/gtdb/output'\n",
    "nucleotide_identity_blast_path = 'pairwise_blast/vOTUs.pairwise_blast.txt'\n",
    "\n",
    "### Read in gtdb taxonomy to append to each\n",
    "gtdb_df = pd.concat([pd.read_csv(f, sep='\\t') for f in glob.glob(gtdb_taxonomy_path+\"/*.summary.tsv\")],\n",
    "                      ignore_index=True)[['user_genome', 'classification']]\n",
    "gtdb_df.columns = ['pairwise_blast_binID', 'pairwise_blast_bin_taxonomy_gtdb']\n",
    "\n",
    "## Read in and process blast results\n",
    "df = pd.read_csv(nucleotide_identity_blast_path, sep='\\t', header=None)\n",
    "# Rename columns\n",
    "df.columns = ['virID', 'vir_length', 'binID', 'bin_len', 'pident', 'match_length', 'mismatch', 'gapopen', 'vir_start', 'vir_end', 'bin_start', 'bin_end', 'evalue', 'bitscore', 'vir_covs']\n",
    "# Filter to only keep matches with: e-value ≤ 0.001 & nucleotide identity ≥ 70% & bit-score ≥ 50 \n",
    "df = df[(df['pident'] >= 70) & (df['evalue'] <= 0.001) & (df['bitscore'] >= 50)]\n",
    "# Add gtdb taxonomy for bins\n",
    "df['pairwise_blast_binID'] = df['binID'].str.replace(r'(contigs).*', r'\\1').str.replace(r'_', r'.').str.replace(r'.sub', r'_sub')\n",
    "df = pd.merge(df, gtdb_df, how=\"left\", on=\"pairwise_blast_binID\").reset_index(drop=True)\n",
    "# Filter to keep columns of interest\n",
    "df = df[['virID', 'pairwise_blast_binID', 'pairwise_blast_bin_taxonomy_gtdb', 'pident', 'evalue', 'bitscore']]\n",
    "df.columns = ['virID', 'pairwise_blast_binID', 'pairwise_blast_bin_taxonomy_gtdb', 'pairwise_blast_pident', 'pairwise_blast_evalue', 'pairwise_blast_bitscore']\n",
    "\n",
    "## filter to only keep top n hits for each vOTU_ID\n",
    "# ERROR handling: If n_hits_threshold greater than or equal to max counts, need to modify n_hits_threshold\n",
    "MAX_VALUE_COUNTS = df.groupby('virID')['virID'].value_counts().max()\n",
    "if n_hits_threshold >= MAX_VALUE_COUNTS:\n",
    "    n_hits_threshold_edit = MAX_VALUE_COUNTS-1\n",
    "else:\n",
    "    n_hits_threshold_edit = n_hits_threshold\n",
    "\n",
    "# Filter based on n_hits_threshold\n",
    "df = df[df.index.isin(df.groupby('virID')['pairwise_blast_evalue'].nsmallest(n_hits_threshold_edit).index.get_level_values(1))].sort_values(by=['virID', 'pairwise_blast_evalue'])\n",
    "# pivot wider and apply suffix to multiple hits\n",
    "df['idx'] = '_'+(df.groupby(['virID']).cumcount() + 1).astype(str)\n",
    "df = (df.pivot_table(index=['virID'], \n",
    "                               columns=['idx'], \n",
    "                               values=['pairwise_blast_binID', 'pairwise_blast_bin_taxonomy_gtdb', 'pairwise_blast_pident', 'pairwise_blast_evalue', 'pairwise_blast_bitscore'], \n",
    "                               aggfunc='first'))\n",
    "df.columns = [''.join(col) for col in df.columns]\n",
    "df = df.reset_index()\n",
    "\n",
    "## Write out summary table\n",
    "df.to_csv('summary_tables/summary_table.pairwise_blast.tsv', sep='\\t', index=False)\n",
    "\n",
    "quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f9f490-4922-4dbb-84cd-0fa744432c95",
   "metadata": {
    "tags": []
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a33cd3b-fb72-4285-a4b8-7f54583c2489",
   "metadata": {},
   "source": [
    "## Host prediction full summary table\n",
    "\n",
    "Generate a summary table combining all host prediction results.\n",
    "\n",
    "NOTE:\n",
    "\n",
    "- Output files to compile:\n",
    "  - crispr spacers: `5.host_prediction/summary_tables/summary_table.crisprSpacers_blastn.tsv`\n",
    "  - binned viral contigs: `5.host_prediction/summary_tables/summary_table.vir_contigs.cobinned.tsv`\n",
    "  - tRNA blast: `5.host_prediction/summary_tables/summary_table.tRNA_blast_virus_host.tsv`\n",
    "  - pairwise blast: `5.host_prediction/summary_tables/summary_table.pairwise_blast.tsv`\n",
    "- The script below also adds vOTU *checkV* stats, as this can be useful when assessing predicted host matches\n",
    "- This will ultimately be put into a script for ease of use. But for now we can use the python code below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c48ed1-0758-4819-94b8-bbf4308a8e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# working directory\n",
    "cd /working/dir\n",
    "\n",
    "# Load python\n",
    "module purge\n",
    "module load Python/3.8.2-gimkl-2020a\n",
    "python3\n",
    "\n",
    "### Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "## Import all results tables\n",
    "# crispr blast\n",
    "crispr_df = pd.read_csv('5.host_prediction/summary_tables/summary_table.crisprSpacers_blastn.tsv', sep='\\t')\n",
    "# binned viral contigs\n",
    "cobinned_df = pd.read_csv('5.host_prediction/summary_tables/summary_table.vir_contigs.cobinned.tsv', sep='\\t')\n",
    "# tRNA blast\n",
    "tRNA_df = pd.read_csv('5.host_prediction/summary_tables/summary_table.tRNA_blast_virus_host.tsv', sep='\\t')\n",
    "# pairwise blast\n",
    "pairwise_df = pd.read_csv('5.host_prediction/summary_tables/summary_table.pairwise_blast.tsv', sep='\\t')\n",
    "# checkV results\n",
    "checkv_df = pd.read_csv('1.viral_identification/6.checkv_vOTUs/vOTUs.checkv_filtered_quality_summary.tsv', sep='\\t', ignore_index=True).drop(columns=['Unnamed: 0', 'provirus', 'proviral_length']).add_prefix('checkv_')\n",
    "\n",
    "## Join all results tables together into summary table\n",
    "summary_df = pd.merge(\n",
    "    tRNA_df, how=\"outer\", on=['virID', 'dataset']).merge(\n",
    "    pairwise_df, how=\"outer\", on=['virID', 'dataset']).merge(\n",
    "    crispr_df, how=\"outer\", on=['virID', 'dataset']).merge(\n",
    "    cobinned_df, how=\"outer\", on=['virID', 'dataset']).sort_values(by=['dataset', 'virID']).reset_index(drop=True)\n",
    "\n",
    "# Trim contigID to match checkv's output (trim off the '__checkv_excised...' bits that we added earlier)\n",
    "summary_df['contig_id'] = summary_df['virID'].str.replace(r'_\\d+__checkv_excised.*', r'', regex=True)\n",
    "\n",
    "# Merge checkv results onto the summary table\n",
    "summary_df = pd.merge(summary_df, checkv_df, how=\"left\", left_on='contig_id', right_on='checkv_contig_id').drop(columns=['contig_id'])\n",
    "\n",
    "## Reorder columns, and write out summary table\n",
    "summary_df=summary_df[['dataset', 'virID'] + \n",
    "                       [col for col in summary_df.columns if 'checkv' in col] + \n",
    "                       [col for col in summary_df.columns if 'cobinned' in col] + \n",
    "                       [col for col in summary_df.columns if 'crispr' in col] + \n",
    "                       [col for col in summary_df.columns if 'tRNA' in col] + \n",
    "                       [col for col in summary_df.columns if 'pairwise' in col]]\n",
    "summary_df.to_csv('5.host_prediction/summary_tables/summary_table.All_host_predictions.tsv', sep='\\t', index=False)\n",
    "\n",
    "quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb45746-c6f4-4939-8aaa-62ec50ffcaff",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "sos": {
   "kernels": [
    [
     "SoS",
     "sos",
     "",
     ""
    ]
   ],
   "version": "0.23.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
