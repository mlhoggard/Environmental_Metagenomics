{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b6b1f00-3b56-4621-86ae-2676f7e74d7d",
   "metadata": {},
   "source": [
    "# Quality filtering and trimming\n",
    "\n",
    "Raw sequence reads need to be filtered and trimmed to remove poor quality reads and trim poor quality ends of reads (and/or any retained adapter sequence). \n",
    "\n",
    "Common options for this include *trimmomatic* or *bbduk*. An example is provided below using *trimmomatic*.\n",
    "\n",
    "The relevant parameters for the filtering and trimming should be decided for each dataset (e.g. based on read length, quality, presence of adapters (which can be assessed via *fastQC*), etc).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b35770b-56aa-4e67-bdc1-71bd94d2896f",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e1d227-9eed-41bb-8453-ddcd81bc8f9f",
   "metadata": {},
   "source": [
    "## Trim and filter reads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c929345f-488a-4884-ad56-13e26fb7a512",
   "metadata": {},
   "source": [
    "#### Trimmomatic: prep raw data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd344752-2438-445a-b47a-2b8875f379a3",
   "metadata": {},
   "source": [
    "Pre-processing: concatenating sample files from multiple lanes\n",
    "\n",
    "- If samples have been run over multiple lanes, concatenate the files for each read (R1 and R2, separately) into single sets of paired read files per sample\n",
    "- Also rename files to a simpler format for downstream use\n",
    "  - For ease of writing for-loops and/or running slurm array jobs, it can be useful to name samples with a shared string followed by a number, e.g. `sample_1`, `sample_2`,... `sample_n`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f91b9b-1698-4038-9198-d63aa60ff7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to working directory\n",
    "cd /working/dir/\n",
    "\n",
    "# Make directory 0.raw_data\n",
    "mkdir 0b.Raw_concat\n",
    "\n",
    "# Set up variables for input files path and output path\n",
    "inpath=0a.Raw/hiseq/fastq\n",
    "outpath=0b.Raw_concat\n",
    "\n",
    "# For each of reads 1 and 2 (R1 and R2), concatenate files from multiple lanes (e.g. L001-L008) into single output files, and rename based on sampleIDs\n",
    "for read in R1 R2;\n",
    "do\n",
    "    cat ${inpath}/*4462-40*_${read}_001.fastq.gz > ${outpath}/S1_${read}.fastq.gz\n",
    "    cat ${inpath}/*4462-44*_${read}_001.fastq.gz > ${outpath}/S2_${read}.fastq.gz\n",
    "    cat ${inpath}/*4462-48*_${read}_001.fastq.gz > ${outpath}/S3_${read}.fastq.gz\n",
    "    cat ${inpath}/*4462-52*_${read}_001.fastq.gz > ${outpath}/S4_${read}.fastq.gz\n",
    "done\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7fec7e-9c4b-4fe7-a760-a9a6cb30cb77",
   "metadata": {},
   "source": [
    "#### Trimmomatic: run\n",
    "\n",
    "Note: \n",
    "\n",
    "- We recommend here also including a search for a truncated version of the adapters, as sometimes these aren't picked up by trimmomatic or fastqc (this is the `ILLUMINACLIP` bit in the script below).\n",
    "  - It may be necessary to check with your sequencing provider what the relevant adapters are and select the shared stretch of sequence to include in `iua.fna` in the script below\n",
    "  - For reference, the sequence included in the example below is based on a truncated section of the Illumina TruSeq adapters\n",
    "- Set `CROP` and `MINLENGTH` to something appropriate for your data (relative to sequence length for this sequencing run)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81b83e0-3ac0-4a1d-b7f4-1f913f77eb14",
   "metadata": {},
   "source": [
    "Slurm array for 9 samples\n",
    "\n",
    "- Change `#SBATCH --array=1-9` for required number of samples\n",
    "  - (This works easiest if your sample names are numbered, e.g. S1_R1.fastq.gz, S2_R1.fastq.gz, etc.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0a00c0-f536-4fcf-8116-232931b0d226",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash -e\n",
    "#SBATCH -A your_project_account\n",
    "#SBATCH -J wgs_1_trimmomatic\n",
    "#SBATCH --time 00:05:00\n",
    "#SBATCH --mem=12GB\n",
    "#SBATCH --array=1-9\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --cpus-per-task=10\n",
    "#SBATCH -e wgs_1_trimmomatic_%a.err\n",
    "#SBATCH -o wgs_1_trimmomatic_%a.out\n",
    "\n",
    "# Load module(s)\n",
    "module purge\n",
    "module load Trimmomatic/0.39-Java-1.8.0_144                \n",
    "\n",
    "# Change to working directory\n",
    "cd /working/dir/\n",
    "\n",
    "# Make output directory \n",
    "mkdir -p 1a.QC_Filtered_trimmomatic/\n",
    "\n",
    "# Set up variables for input path and output path\n",
    "inpath=0b.Raw_concat\n",
    "outpath=1a.QC_Filtered_trimmomatic\n",
    "\n",
    "# Make adapter file if not already created\n",
    "if [ ! -f iua.fna ]; then\n",
    "    echo \">FastQC_adapter\" > iua.fna\n",
    "    echo \"AGATCGGAAGAG\" >> iua.fna\n",
    "fi\n",
    "\n",
    "## Water filter samples              \n",
    "# Quality filter and trim \n",
    "srun trimmomatic PE -threads 10 -phred33 -quiet \\\n",
    "${inpath}/S${SLURM_ARRAY_TASK_ID}_R1.fastq.gz ${inpath}/S${SLURM_ARRAY_TASK_ID}_R2.fastq.gz \\\n",
    "${outpath}/S${SLURM_ARRAY_TASK_ID}_R1.fastq S${SLURM_ARRAY_TASK_ID}_R1.single1.fastq \\\n",
    "${outpath}/S${SLURM_ARRAY_TASK_ID}_R2.fastq S${SLURM_ARRAY_TASK_ID}_R2.single2.fastq \\\n",
    "ILLUMINACLIP:iua.fna:1:25:7 CROP:115 SLIDINGWINDOW:4:30 MINLEN:50\n",
    "\n",
    "# Tidy up the singleton reads\n",
    "cat S${SLURM_ARRAY_TASK_ID}_R1.single1.fastq S${SLURM_ARRAY_TASK_ID}_R2.single2.fastq \\\n",
    "> ${outpath}/S${SLURM_ARRAY_TASK_ID}_single.fastq\n",
    "\n",
    "rm S${SLURM_ARRAY_TASK_ID}_R1.single1.fastq S${SLURM_ARRAY_TASK_ID}_R2.single2.fastq\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318a1393-e946-4580-b799-c338acef5326",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eec9977-4ab5-4ed1-977d-b9b224a8e356",
   "metadata": {},
   "source": [
    "## FastQC analysis of trimmed reads \n",
    "\n",
    "Examine the quality of the trimmed reads via *fastQC* and *multiQC*. \n",
    "\n",
    "Some important things to look for include: \n",
    "\n",
    "- Sequence counts: this will give you an indication if some samples are have more or less sequences associated with them. This can be useful to bear in mind if you are missing samples later; it may just be that there were no quality sequences recovered from those samples to begin with.\n",
    "- Overall sequencing quality and quality scores across reads\n",
    "  - incl. if the *ends* of sequences have high error rate and may require further trimming\n",
    "- GC content of reads\n",
    "- Retained adapter sequences which will require further trimming\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0a7f6a-4198-4b4a-a3c2-cc7d799eed82",
   "metadata": {},
   "source": [
    "#### FastQC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09819de3-9bd7-48b9-89b8-7266450dbb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash -e\n",
    "#SBATCH -A your_project_account\n",
    "#SBATCH -J wgs_1_qc_fastqc\n",
    "#SBATCH --time 01:00:00\n",
    "#SBATCH --mem 1GB\n",
    "#SBATCH --array=1-9\n",
    "#SBATCH --ntasks 1\n",
    "#SBATCH --cpus-per-task 2\n",
    "#SBATCH -e wgs_1_qc_fastqc_%a.err\n",
    "#SBATCH -o wgs_1_qc_fastqc_%a.out\n",
    "\n",
    "# Set up working directories\n",
    "cd /working/dir/\n",
    "mkdir -p 1a.QC_Filtered_trimmomatic/fastqc/\n",
    "\n",
    "# load modules\n",
    "module load FastQC/0.11.9\n",
    "module load MultiQC/1.9-gimkl-2020a-Python-3.8.2\n",
    "\n",
    "# Run fastqc on each sample\n",
    "srun fastqc \\\n",
    "-o 1a.QC_Filtered_trimmomatic/fastqc/ \\\n",
    "1a.QC_Filtered_trimmomatic/S${SLURM_ARRAY_TASK_ID}_R1.fastq 1a.QC_Filtered_trimmomatic/S${SLURM_ARRAY_TASK_ID}_R2.fastq\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2ad0e0-7583-4e2d-96e5-7ece716dbddf",
   "metadata": {},
   "source": [
    "#### MultiQC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3f8b98-963b-4c78-9900-1b7325e12aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash -e\n",
    "#SBATCH -A your_project_account\n",
    "#SBATCH -J wgs_1_qc_multiqc\n",
    "#SBATCH --time 00:10:00\n",
    "#SBATCH --mem 1GB\n",
    "#SBATCH --ntasks 1\n",
    "#SBATCH --cpus-per-task 2\n",
    "#SBATCH -e wts_1_qc_multiqc.err\n",
    "#SBATCH -o wts_1_qc_multiqc.out\n",
    "\n",
    "# Set up working directories\n",
    "cd /working/dir\n",
    "\n",
    "# load modules\n",
    "module load FastQC/0.11.9\n",
    "module load MultiQC/1.9-gimkl-2020a-Python-3.8.2\n",
    "\n",
    "# Run multiqc to generate report for all samples\n",
    "srun multiqc -f \\\n",
    "-o 1a.QC_Filtered_trimmomatic/fastqc/ \\\n",
    "1a.QC_Filtered_trimmomatic/fastqc/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb4706f-a0f0-45a3-8246-06536ae47059",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cba23d-e5af-4834-9297-3c822cfb9832",
   "metadata": {},
   "source": [
    "## Optional: Filter out host sequences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1301a2-4f6e-42d0-a483-b62fc43b7d17",
   "metadata": {},
   "source": [
    "#### Preamble\n",
    "\n",
    "Metagenome data derived from microbial communities associated with a host should ideally be filtered to remove any reads originating from host DNA. This may improve the quality and efficiency of downstream data processing (since we will no longer be processing a bunch of data that we are likely not interested in), and is also an important consideration when working with metagenomes that may include data of a sensitive nature (and which may also need to be removed prior to making the data publicly available). This is especially important for any studies involving human subjects or those involving samples derived from taonga species.\n",
    "\n",
    "There are several approaches that can be used to achieve this. The general principle is to map your reads to a reference genome (e.g. human genome) and remove those reads that map to the reference from the dataset. \n",
    "\n",
    "The steps below provide an example using *BBMap* to map against a masked human reference genome and retain only those reads that do *not* map to the reference. Here we are mapping the quality-filtered reads against a pre-prepared human genome that has been processed to mask sections of the genome, including those that: are presumbed microbial contaminant in the reference; have high homology to microbial genes/genomes (e.g. ribosomes); or those that are of low complexity. This ensures that reads that would normally map to these sections of the human genome are *not* removed from the dataset (as genuine microbial reads that we wish to retain might also map to these regions), while all reads mapping to the rest of the human genome are removed.\n",
    "\n",
    "Notes: \n",
    "\n",
    "- The same process can be used to remove DNA matching other hosts (e.g. mouse), however you would need to search if anyone has prepared (and made available) a masked version of the reference genome, or create a masked version using bbmask. The creator of BBMap has made available masked human, mouse, cat, and dog genomes. More information, including links to these references and instructions on how to generate a masked genome for other taxa, can be found within [this thread](http://seqanswers.com/forums/showthread.php?t=42552).\n",
    "- You can also map to a *non*-masked reference, with the caveat that you may filter out some genuninely microbial sequences that are similar to regions in the host genome.\n",
    "- This process may be more complicated if a reference genome for your host taxa is not readily available. In this case an alternative method would need to be employed (for example: predicting taxonomy via Kraken2 and then filtering out all reads that map to the pylum or kingdom of your host taxa).\n",
    "- If you are interested in viruses, and the virus of interest happens to be integrated in the reference genome, then this data may be lost in this process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686752b1-f41d-4ff9-9aa8-6c7df7ddce22",
   "metadata": {},
   "source": [
    "#### Download reference genome\n",
    "\n",
    "Download the host reference genome of interest. Select pre-prepared masked references are available [here](http://seqanswers.com/forums/showthread.php?t=42552), or download your own non-masked reference.\n",
    "\n",
    "For reference:\n",
    "\n",
    "- The masked human reference genome is available from [here](https://drive.google.com/file/d/0B3llHR93L14wd0pSSnFULUlhcUk/edit)\n",
    "- The masked mouse reference genome is available from [here](https://drive.google.com/file/d/0B3llHR93L14wYmJYNm9EbkhMVHM/view)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4d5c60-3c52-4df0-ad55-661a44c14e39",
   "metadata": {},
   "source": [
    "#### Host filtering: Build BBMap index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a9b545-fd0d-4ae1-bab6-e7ff76b62e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash -e\n",
    "#SBATCH -A your_project_account\n",
    "#SBATCH -J wgs_1_hostfilt_mapping_index\n",
    "#SBATCH --time 00:20:00\n",
    "#SBATCH --mem 23GB\n",
    "#SBATCH --ntasks 1\n",
    "#SBATCH --cpus-per-task 1\n",
    "#SBATCH -e wgs_1_hostfilt_mapping_index.err\n",
    "#SBATCH -o wgs_1_hostfilt_mapping_index.out\n",
    "\n",
    "# working directories\n",
    "cd /working/dir/\n",
    "mkdir -p 1b.QC_Filtered_host/\n",
    "cd 1b.QC_Filtered_host/\n",
    "\n",
    "# Load BBMap module\n",
    "module purge\n",
    "module load BBMap/38.81-gimkl-2020a\n",
    "\n",
    "# Build BBMap index of reference genome\n",
    "srun bbmap.sh ref=/path/to/reference/genome.fa.gz -Xmx23g\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35da7492-27c0-4d25-9ae5-50efdc515d31",
   "metadata": {},
   "source": [
    "#### Host filtering: per-sample BBMap read mapping, slurm array\n",
    "\n",
    "Note:\n",
    "\n",
    "- This step outputs fastq files where reads that map to the reference genome have been filtered out.\n",
    "- The output from `outu` is the filtered file for downstream use.\n",
    "- Host filtering here is run as a two step process for each sample: first, on the paired reads (R1 and R2), and then again for the unpaired (single) reads file.\n",
    "- The parameters are set based on the recomendations for host filtering outlined [here](http://seqanswers.com/forums/showthread.php?t=42552)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcdb55b-71ae-47d9-9620-9b63779d4e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH -A your_project_account\n",
    "#SBATCH -J wgs_1_hostfilt_mapping\n",
    "#SBATCH --time 01:00:00\n",
    "#SBATCH --mem 28GB\n",
    "#SBATCH --ntasks 1\n",
    "#SBATCH --array=1-9\n",
    "#SBATCH --cpus-per-task 32\n",
    "#SBATCH -e wgs_1_hostfilt_mapping_%a.err\n",
    "#SBATCH -o wgs_1_hostfilt_mapping_%a.out\n",
    "\n",
    "# Set up working directories\n",
    "cd /working/dir/1b.QC_Filtered_host/\n",
    "\n",
    "# Load BBMap module\n",
    "module purge\n",
    "module load BBMap/38.81-gimkl-2020a\n",
    "\n",
    "## Run bbmap\n",
    "\n",
    "# Paired reads (R1 and R2)\n",
    "srun bbmap.sh -Xmx26g -t=32 \\\n",
    "minid=0.95 maxindel=3 bwr=0.16 bw=12 quickmatch fast minhits=2 qtrim=rl trimq=10 untrim \\\n",
    "in1=../1a.QC_Filtered_trimmomatic/S${SLURM_ARRAY_TASK_ID}_R1.fastq \\\n",
    "in2=../1a.QC_Filtered_trimmomatic/S${SLURM_ARRAY_TASK_ID}_R2.fastq \\\n",
    "outu1=S${SLURM_ARRAY_TASK_ID}_R1_hostFilt.fastq \\\n",
    "outu2=S${SLURM_ARRAY_TASK_ID}_R2_hostFilt.fastq\n",
    "\n",
    "# Unpaired (single) reads\n",
    "srun bbmap.sh -Xmx26g -t=32 \\\n",
    "minid=0.95 maxindel=3 bwr=0.16 bw=12 quickmatch fast minhits=2 qtrim=rl trimq=10 untrim \\\n",
    "in=../1a.QC_Filtered_trimmomatic/S${SLURM_ARRAY_TASK_ID}_single.fastq \\\n",
    "outu=S${SLURM_ARRAY_TASK_ID}_single_hostFilt.fastq\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f952663-156d-4fe9-901e-8e86b3238a05",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57128827-4b5a-4cce-9131-ff487726c8c6",
   "metadata": {},
   "source": [
    "## Optional: Post-filtering assessment\n",
    "\n",
    "It pays to check that the filtering and trimming process has done what you expected, and that seqeuences in the filtered and trimmed output files are now of the standard that you want to use for all downstream processing.\n",
    "\n",
    "This can be done via:\n",
    "\n",
    "1. Comparing the numbers of reads in the raw data, post-trimming, and post-host DNA removal to make sure it hasn't filtered out more reads than you'd expect.\n",
    "1. Running the filtered outputs back through fastqc to check that sequences are generally of a length and quality that you'd expect after the trimming and filtering process (and that no adapter sequence has been retained)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a20263-4902-4abc-b6cb-d128a6c49235",
   "metadata": {},
   "source": [
    "#### Checking library sizes: Summary file of read counts during filtering process\n",
    "\n",
    "Use line counts of the files (`(wc -l)/4`) to summarise read counts for each sample at each of the filtering steps.\n",
    "\n",
    "The below outputs to `Read_counts_summary.txt`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64dfb21-ac28-44be-bf22-7c2c6023b9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH -A your_project_account\n",
    "#SBATCH -J wgs_1_qc_summary\n",
    "#SBATCH --time 02:00:00\n",
    "#SBATCH --mem 1GB\n",
    "#SBATCH --ntasks 1\n",
    "#SBATCH --cpus-per-task 1\n",
    "#SBATCH -e wgs_1_qc_summary.err\n",
    "#SBATCH -o wgs_1_qc_summary.out\n",
    "\n",
    "# Set up working directories\n",
    "cd /working/dir/\n",
    "\n",
    "# Set up variables for input files path and output path\n",
    "raw_path=0b.raw_data_concat\n",
    "trimmed_path=1a.QC_Filtered_trimmomatic\n",
    "host_filt_path=1b.QC_Filtered_host\n",
    "\n",
    "# Set up read_counts_summary file headers\n",
    "echo -e \"Sample\\traw_read_count\\tTrimmed (paired)\\tTrimmed (single)\\tHost-filtered (paired)\\tHost-filtered (single)\" > Read_counts_summary.txt\n",
    "\n",
    "# Summarise read counts for all samples and add to Read_counts_summary.txt\n",
    "for i in {1..9};\n",
    "do\n",
    "    # Summarise the raw data, trimmed, and host-filtered files\n",
    "    count_raw=$(($(zcat ${raw_path}/S${i}_R1.fastq.gz | wc -l)/4))\n",
    "    count_trimmed_paired=$(($(zcat ${phix_filt_path}/S${i}_R1_Filt.fastq.gz | wc -l)/4))\n",
    "    count_trimmed_single=$(($(zcat ${phix_filt_path}/S${i}_single_Filt.fastq.gz | wc -l)/4))\n",
    "    count_hostFilt_paired=$(($(cat ${host_filt_path}/S${i}_R1_hostFilt.fastq | wc -l)/4))\n",
    "    count_hostFilt_single=$(($(cat ${host_filt_path}/S${i}_single_hostFilt.fastq | wc -l)/4))\n",
    "    # write results to summary file\n",
    "    echo \"|S\"${i}\"|\"${count_raw}\"|\"${count_trimmed_paired}\"|\"${count_trimmed_single}\"|\"${count_hostFilt_paired}\"|\"${count_hostFilt_single}\"|\" >> Read_counts_summary.txt\n",
    "done\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefb87e9-d7a1-4b82-9b0b-552aab519fef",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
